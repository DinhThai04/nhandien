"""
Module OCR Engine - Nh·∫≠n d·∫°ng text t·ª´ h√¨nh ·∫£nh
"""
import pytesseract
from PIL import Image
import cv2
import numpy as np
import logging
import os
import sys
from pathlib import Path

# Th√™m th∆∞ m·ª•c config v√†o path
sys.path.append(str(Path(__file__).parent.parent))
from config.config import TESSERACT_CMD, OCR_LANG, MIN_CONFIDENCE

# C·∫•u h√¨nh Tesseract
if os.path.exists(TESSERACT_CMD):
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OCREngine:
    """Engine x·ª≠ l√Ω OCR ƒë·ªÉ nh·∫≠n d·∫°ng text t·ª´ ·∫£nh"""

    def __init__(self, lang: str = OCR_LANG):
        """
        Kh·ªüi t·∫°o OCR Engine

        Args:
            lang: Ng√¥n ng·ªØ nh·∫≠n d·∫°ng (m·∫∑c ƒë·ªãnh: vie+eng)
        """
        self.lang = lang
        self.logger = logger
        self.min_confidence = MIN_CONFIDENCE

        # Ki·ªÉm tra Tesseract
        self._check_tesseract()

    def _check_tesseract(self):
        """Ki·ªÉm tra Tesseract ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a"""
        try:
            version = pytesseract.get_tesseract_version()
            self.logger.info(f"‚úÖ Tesseract version: {version}")

            # Ki·ªÉm tra ng√¥n ng·ªØ c√≥ s·∫µn
            try:
                langs = pytesseract.get_languages()
                if 'vie' in langs:
                    self.logger.info("‚úÖ Vietnamese language pack available")
                else:
                    self.logger.warning("‚ö†Ô∏è Vietnamese language pack not found. OCR accuracy may be reduced.")
            except:
                pass

        except Exception as e:
            self.logger.error(f"‚ùå L·ªói: Tesseract ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c c·∫•u h√¨nh sai. {e}")
            self.logger.info("üìã H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t Tesseract:")
            self.logger.info("   Windows: https://github.com/UB-Mannheim/tesseract/wiki")
            self.logger.info("   Linux: sudo apt-get install tesseract-ocr tesseract-ocr-vie")
            raise RuntimeError("Tesseract OCR not properly configured")

    def extract_text(self, image_path, config: str = '--psm 6') -> str:
        """
        Tr√≠ch xu·∫•t text t·ª´ ·∫£nh

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c numpy array
            config: C·∫•u h√¨nh Tesseract (PSM - Page Segmentation Mode)
                   --psm 3: Fully automatic (default)
                   --psm 6: Assume a single uniform block of text
                   --psm 11: Sparse text

        Returns:
            str: Text ƒë∆∞·ª£c nh·∫≠n d·∫°ng
        """
        try:
            # ƒê·ªçc ·∫£nh n·∫øu l√† ƒë∆∞·ªùng d·∫´n, ho·∫∑c d√πng tr·ª±c ti·∫øp n·∫øu l√† numpy array
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                # Convert numpy array to PIL Image
                import cv2
                if len(image_path.shape) == 3:
                    image = Image.fromarray(cv2.cvtColor(image_path, cv2.COLOR_BGR2RGB))
                else:
                    image = Image.fromarray(image_path)

            # OCR v·ªõi config
            text = pytesseract.image_to_string(
                image,
                lang=self.lang,
                config=config
            )

            self.logger.info(f"Tr√≠ch xu·∫•t text th√†nh c√¥ng t·ª´: {image_path}")
            return text.strip()

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t text: {e}")
            return ""

    def extract_text_with_confidence(self, image_path) -> dict:
        """
        Tr√≠ch xu·∫•t text k√®m ƒë·ªô tin c·∫≠y

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ho·∫∑c numpy array

        Returns:
            dict: {
                'text': str,
                'confidence': float,
                'details': list of dict
            }
        """
        try:
            # ƒê·ªçc ·∫£nh n·∫øu l√† ƒë∆∞·ªùng d·∫´n, ho·∫∑c d√πng tr·ª±c ti·∫øp n·∫øu l√† numpy array
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                # Convert numpy array to PIL Image
                import cv2
                if len(image_path.shape) == 3:
                    image = Image.fromarray(cv2.cvtColor(image_path, cv2.COLOR_BGR2RGB))
                else:
                    image = Image.fromarray(image_path)

            # L·∫•y d·ªØ li·ªáu chi ti·∫øt
            data = pytesseract.image_to_data(
                image,
                lang=self.lang,
                output_type=pytesseract.Output.DICT
            )

            # L·ªçc c√°c t·ª´ c√≥ ƒë·ªô tin c·∫≠y ƒë·ªß
            filtered_text = []
            confidences = []
            details = []

            n_boxes = len(data['text'])
            for i in range(n_boxes):
                confidence = int(data['conf'][i])
                text = data['text'][i].strip()

                if confidence > 0 and text:
                    if confidence >= self.min_confidence:
                        filtered_text.append(text)
                        confidences.append(confidence)

                    details.append({
                        'text': text,
                        'confidence': confidence,
                        'left': data['left'][i],
                        'top': data['top'][i],
                        'width': data['width'][i],
                        'height': data['height'][i]
                    })

            avg_confidence = sum(confidences) / len(confidences) if confidences else 0

            result = {
                'text': ' '.join(filtered_text),
                'confidence': round(avg_confidence, 2),
                'details': details
            }

            self.logger.info(f"ƒê·ªô tin c·∫≠y trung b√¨nh: {avg_confidence:.2f}%")
            return result

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t text v·ªõi confidence: {e}")
            return {'text': '', 'confidence': 0, 'details': []}

    def extract_structured_data(self, image_path: str) -> dict:
        """
        Tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c t·ª´ nh√£n b∆∞u ki·ªán

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh

        Returns:
            dict: Th√¥ng tin ƒë∆∞·ª£c tr√≠ch xu·∫•t
        """
        result = {
            'recipient_name': '',
            'phone': '',
            'address': '',
            'postal_code': '',
            'raw_text': '',
            'confidence': 0
        }

        try:
            # L·∫•y text v·ªõi confidence
            ocr_result = self.extract_text_with_confidence(image_path)
            result['raw_text'] = ocr_result['text']
            result['confidence'] = ocr_result['confidence']

            # Ph√¢n t√≠ch text
            lines = result['raw_text'].split('\n')

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # T√¨m s·ªë ƒëi·ªán tho·∫°i
                if self._is_phone_number(line):
                    result['phone'] = self._extract_phone_number(line)

                # T√¨m m√£ b∆∞u ch√≠nh
                postal = self._extract_postal_code(line)
                if postal:
                    result['postal_code'] = postal

                # T√¨m ƒë·ªãa ch·ªâ (d√≤ng ch·ª©a t·ª´ kh√≥a ƒë·ªãa ch·ªâ)
                if any(keyword in line.lower() for keyword in
                      ['ƒë∆∞·ªùng', 'ph∆∞·ªùng', 'qu·∫≠n', 'huy·ªán', 't·ªânh', 'th√†nh ph·ªë']):
                    result['address'] += line + ' '

            # L√†m s·∫°ch d·ªØ li·ªáu
            result['address'] = result['address'].strip()

            self.logger.info("Tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c th√†nh c√¥ng")
            return result

        except Exception as e:
            self.logger.error(f"L·ªói khi tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c: {e}")
            return result

    def _is_phone_number(self, text: str) -> bool:
        """Ki·ªÉm tra xem text c√≥ ph·∫£i s·ªë ƒëi·ªán tho·∫°i kh√¥ng"""
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
        cleaned = ''.join(c for c in text if c.isdigit())

        # S·ªë ƒëi·ªán tho·∫°i Vi·ªát Nam: 10-11 s·ªë, b·∫Øt ƒë·∫ßu b·∫±ng 0
        return len(cleaned) >= 10 and len(cleaned) <= 11 and cleaned.startswith('0')

    def _extract_phone_number(self, text: str) -> str:
        """Tr√≠ch xu·∫•t s·ªë ƒëi·ªán tho·∫°i t·ª´ text"""
        import re

        # Pattern cho s·ªë ƒëi·ªán tho·∫°i Vi·ªát Nam
        patterns = [
            r'0\d{9,10}',  # 10-11 s·ªë b·∫Øt ƒë·∫ßu b·∫±ng 0
            r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}',  # Format c√≥ d·∫•u ph√¢n c√°ch
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                phone = match.group()
                # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
                return ''.join(c for c in phone if c.isdigit())

        return ''

    def _extract_postal_code(self, text: str) -> str:
        """Tr√≠ch xu·∫•t m√£ b∆∞u ch√≠nh"""
        import re

        # M√£ b∆∞u ch√≠nh Vi·ªát Nam: 5-6 s·ªë
        pattern = r'\b\d{5,6}\b'
        match = re.search(pattern, text)

        if match:
            return match.group()

        return ''

    def visualize_ocr_result(self, image_path: str, output_path: str) -> None:
        """
        V·∫Ω k·∫øt qu·∫£ OCR l√™n ·∫£nh

        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh g·ªëc
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh k·∫øt qu·∫£
        """
        try:
            # ƒê·ªçc ·∫£nh
            image = cv2.imread(image_path)

            # L·∫•y d·ªØ li·ªáu OCR
            pil_image = Image.open(image_path)
            data = pytesseract.image_to_data(
                pil_image,
                lang=self.lang,
                output_type=pytesseract.Output.DICT
            )

            # V·∫Ω bounding boxes
            n_boxes = len(data['text'])
            for i in range(n_boxes):
                confidence = int(data['conf'][i])
                text = data['text'][i].strip()

                if confidence > self.min_confidence and text:
                    x, y, w, h = (data['left'][i], data['top'][i],
                                 data['width'][i], data['height'][i])

                    # V·∫Ω rectangle
                    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

                    # Ghi text v√† confidence
                    label = f"{text} ({confidence}%)"
                    cv2.putText(image, label, (x, y - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            # L∆∞u ·∫£nh
            cv2.imwrite(output_path, image)
            self.logger.info(f"ƒê√£ l∆∞u ·∫£nh visualization t·∫°i: {output_path}")

        except Exception as e:
            self.logger.error(f"L·ªói khi visualization: {e}")


if __name__ == "__main__":
    # Test
    ocr = OCREngine()
    print("OCREngine module loaded successfully!")
